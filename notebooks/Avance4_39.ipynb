{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W94YPusvub-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e9dce8-584c-4aa7-ac34-106f05419e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.274 in /usr/local/lib/python3.10/dist-packages (0.0.274)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (0.0.92)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (2.10.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (1.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.274) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.274) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.274) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.274) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.274) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.274) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.274) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (24.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (1.0.0)\n",
            "Requirement already satisfied: gpt4all==1.0.8 in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all==1.0.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all==1.0.8) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==1.0.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==1.0.8) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==1.0.8) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==1.0.8) (2024.2.2)\n",
            "Requirement already satisfied: chromadb==0.4.7 in /usr/local/lib/python3.10/dist-packages (0.4.7)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (1.10.15)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (0.7.2)\n",
            "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (0.99.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (4.11.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (3.5.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (1.18.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (6.4.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.7) (4.1.3)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.7) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.7) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.7) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.7) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.7) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.7) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.7) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.7) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.7) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.7) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb==0.4.7) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.7) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.7) (2.0.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb==0.4.7) (0.23.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (6.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.7) (12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.7) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.7) (2023.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.7) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.7) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.7) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.7) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.7) (1.2.1)\n",
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.1.81)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: urllib3==2.0.4 in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: PyMuPDF==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.0 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF==1.23.1) (1.23.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: unstructured==0.10.8 in /usr/local/lib/python3.10/dist-packages (0.10.8)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured==0.10.8) (2.12.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.10.8) (2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji->unstructured==0.10.8) (4.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.10.8) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.10.8) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.10.8) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.10.8) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.10.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.10.8) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.10.8) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.10.8) (2024.2.2)\n",
            "Requirement already satisfied: extract-msg==0.45.0 in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: imapclient<3,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (2.3.1)\n",
            "Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (0.46)\n",
            "Requirement already satisfied: tzlocal<6,>=4.2 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (5.2)\n",
            "Requirement already satisfied: compressed-rtf<2,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (1.0.6)\n",
            "Requirement already satisfied: ebcdic<2,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (1.1.1)\n",
            "Requirement already satisfied: beautifulsoup4<4.13,>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (4.12.3)\n",
            "Requirement already satisfied: RTFDE<0.2,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (0.1.1)\n",
            "Requirement already satisfied: red-black-tree-mod==1.20 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.45.0) (1.20)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<4.13,>=4.11.1->extract-msg==0.45.0) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imapclient<3,>=2.3.0->extract-msg==0.45.0) (1.16.0)\n",
            "Requirement already satisfied: lark==1.1.8 in /usr/local/lib/python3.10/dist-packages (from RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (1.1.8)\n",
            "Requirement already satisfied: oletools>=0.56 in /usr/local/lib/python3.10/dist-packages (from RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (0.60.1)\n",
            "Requirement already satisfied: pyparsing<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (2.4.7)\n",
            "Requirement already satisfied: easygui in /usr/local/lib/python3.10/dist-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (0.98.3)\n",
            "Requirement already satisfied: colorclass in /usr/local/lib/python3.10/dist-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (2.2.2)\n",
            "Requirement already satisfied: pcodedmp>=1.2.5 in /usr/local/lib/python3.10/dist-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (1.2.6)\n",
            "Requirement already satisfied: msoffcrypto-tool in /usr/local/lib/python3.10/dist-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (5.4.1)\n",
            "Requirement already satisfied: cryptography>=35.0 in /usr/local/lib/python3.10/dist-packages (from msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=35.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=35.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.0->extract-msg==0.45.0) (2.22)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandoc==2.3 in /usr/local/lib/python3.10/dist-packages (2.3)\n",
            "Requirement already satisfied: plumbum in /usr/local/lib/python3.10/dist-packages (from pandoc==2.3) (1.8.3)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from pandoc==2.3) (3.11)\n",
            "Requirement already satisfied: pypandoc==1.11 in /usr/local/lib/python3.10/dist-packages (1.11)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: jq in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.274\n",
        "!pip install gpt4all==1.0.8\n",
        "!pip install chromadb==0.4.7\n",
        "!pip install llama-cpp-python\n",
        "!pip install urllib3==2.0.4\n",
        "!pip install PyMuPDF==1.23.1\n",
        "!pip install python-dotenv==1.0.0\n",
        "!pip install unstructured==0.10.8\n",
        "!pip install extract-msg==0.45.0\n",
        "!pip install tabulate==0.9.0\n",
        "!pip install pandoc==2.3\n",
        "!pip install pypandoc==1.11\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install sentence_transformers\n",
        "!pip install jq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Library Imports\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Third-Party Library Imports\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Langchain Imports\n",
        "from langchain.document_loaders import (\n",
        "    CSVLoader,\n",
        "    EverNoteLoader,\n",
        "    PyMuPDFLoader,\n",
        "    TextLoader,\n",
        "    JSONLoader\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import GPT4All, LlamaCpp\n",
        "from transformers import AutoModel, AutoTokenizer,  BertModel, BertTokenizer\n",
        "\n",
        "# ChromaDB Imports\n",
        "from chromadb.config import Settings\n",
        "import chromadb\n",
        "\n",
        "# Argument Parsing\n",
        "import argparse\n",
        "\n",
        "import torch  # Import PyTorch to check GPU availability"
      ],
      "metadata": {
        "id": "8vR6uFvsv0I0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"/content/db/\"\n",
        "#persist_directory = \"/content/drive/MyDrive/Colab/db/\"\n",
        "model_type = \"GPT4All\"\n",
        "model_path = \"/content/drive/MyDrive/Colab/Models/ggml-gpt4all-j-v1.3-groovy.bin\"\n",
        "#model_type = \"LLAMA\"\n",
        "#model_path = \"/content/drive/MyDrive/Colab/Models/llama_2_7b_chat_ggmlv3_q4_0.bin\"\n",
        "#source_directory = \"/content/drive/MyDrive/Colab/SOR/\"\n",
        "source_directory = \"./sor/\"\n",
        "embeddings_model_name = \"all-MiniLM-L6-v2\"\n",
        "model_n_ctx = 1000\n",
        "model_n_batch = 8\n",
        "target_source_chunks = 4\n",
        "chunk_size = 500\n",
        "chunk_overlap = 50"
      ],
      "metadata": {
        "id": "-lVGkrCowkZW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LXhY9iysa-ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b809df0-acee-4b5a-f1f9-003aef291776"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the specified source directory\n",
        "archivos = os.listdir(source_directory)\n",
        "\n",
        "# Count the number of files in the directory\n",
        "cantidad_de_archivos = len(archivos)\n",
        "\n",
        "# Print the number of files in the directory\n",
        "print(f\"The folder '{source_directory}' contains {cantidad_de_archivos} files.\")\n"
      ],
      "metadata": {
        "id": "jwRoOfK7brJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422ef380-f836-4ad4-f787-8f44b956c6fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder './sor/' contains 3 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "nPbkWegG7X8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0884f2-6dcb-4d6c-e872-6d2d2a85bcde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings using Hugging Face model\n",
        "# The 'embeddings_model_name' specifies the pre-trained model to use for embeddings.\n",
        "\n",
        "# Load the model and tokenizer from transformers, specifying the device\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n"
      ],
      "metadata": {
        "id": "9GbEaG35wm34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd92a0e-5785-49d3-c10d-34f468841e14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map file extensions to document loaders and their arguments\n",
        "LOADER_MAPPING = {\n",
        "    \".csv\": (CSVLoader, {}),  # Use the CSVLoader for .csv files with no additional arguments.\n",
        "    \".pdf\": (PyMuPDFLoader, {}),  # Use the PyMuPDFLoader for .pdf files with no additional arguments.\n",
        "    \".txt\": (TextLoader, {\"encoding\": \"utf8\"}) # Use the TextLoader for .txt files with the specified UTF-8 encoding.\n",
        "    # Add more mappings for other file extensions and loaders as needed\n",
        "}\n"
      ],
      "metadata": {
        "id": "RmhR8Aebyeo_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_single_document(file_path: str) -> List[Document]:\n",
        "    # Extract the file extension from the given file path.\n",
        "    ext = \".\" + file_path.rsplit(\".\", 1)[-1].lower()\n",
        "\n",
        "    # Check if the file extension is in the LOADER_MAPPING dictionary.\n",
        "    if ext in LOADER_MAPPING:\n",
        "        # Get the loader class and loader arguments for the specified extension.\n",
        "        loader_class, loader_args = LOADER_MAPPING[ext]\n",
        "\n",
        "        # Create an instance of the loader class with the specified file path and arguments.\n",
        "        loader = loader_class(file_path, **loader_args)\n",
        "\n",
        "        # Load the document using the loader and return it.\n",
        "        return loader.load()\n",
        "\n",
        "    # If the file extension is not supported, raise a ValueError.\n",
        "    raise ValueError(f\"Unsupported file extension '{ext}'\")"
      ],
      "metadata": {
        "id": "otUBD37exX5J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(source_dir: str, ignored_files: List[str] = []) -> List[Document]:\n",
        "    # Find all files in the source directory with extensions specified in LOADER_MAPPING.\n",
        "    all_files = []\n",
        "    for ext in LOADER_MAPPING:\n",
        "        all_files.extend(\n",
        "            glob.glob(os.path.join(source_dir, f\"**/*{ext.lower()}\"), recursive=True)\n",
        "        )\n",
        "        all_files.extend(\n",
        "            glob.glob(os.path.join(source_dir, f\"**/*{ext.upper()}\"), recursive=True)\n",
        "        )\n",
        "\n",
        "    # Filter out files that are in the ignored_files list.\n",
        "    filtered_files = [file_path for file_path in all_files if file_path not in ignored_files]\n",
        "\n",
        "    # Use a multiprocessing Pool to load documents in parallel.\n",
        "    with Pool(processes=os.cpu_count()) as pool:\n",
        "        results = []\n",
        "        # Create a progress bar for loading documents.\n",
        "        with tqdm(total=len(filtered_files), desc='Loading new documents', ncols=80) as pbar:\n",
        "            for i, docs in enumerate(pool.imap_unordered(load_single_document, filtered_files)):\n",
        "                results.extend(docs)\n",
        "                pbar.update()\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "Qd4JTeSExbXS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_documents(ignored_files: List[str] = []) -> List[Document]:\n",
        "    # Print a message indicating that documents are being loaded from the specified source directory.\n",
        "    print(f\"Loading documents from {source_directory}\")\n",
        "\n",
        "    # Load documents from the source directory, excluding any ignored files.\n",
        "    documents = load_documents(source_directory, ignored_files)\n",
        "\n",
        "    # Check if there are no documents to process and exit if that's the case.\n",
        "    if not documents:\n",
        "        print(\"No new documents to load\")\n",
        "        exit(0)\n",
        "\n",
        "    # Print the number of loaded documents and the source directory.\n",
        "    print(f\"Loaded {len(documents)} new documents from {source_directory}\")\n",
        "\n",
        "    # Create a text splitter with the specified chunk size and overlap.\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "    # Split the loaded documents into chunks of text using the text splitter.\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Print the number of text chunks created and the maximum chunk size.\n",
        "    print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} tokens each)\")\n",
        "\n",
        "    # Return the resulting text chunks.\n",
        "    return texts"
      ],
      "metadata": {
        "id": "kfG4Hux3xegk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def does_vectorstore_exist(persist_directory: str, embeddings: HuggingFaceEmbeddings) -> bool:\n",
        "    # Create a Chroma vector store instance with the specified persist directory and embeddings.\n",
        "    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "\n",
        "    # Get the 'documents' data from the vector store. If it's empty, return False; otherwise, return True.\n",
        "    if not db.get()['documents']:\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "WIborcoMxhEC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the vector store already exists in the specified directory with the given embeddings.\n",
        "if does_vectorstore_exist(persist_directory, embeddings):\n",
        "    # If the vector store exists, append to it.\n",
        "    print(f\"Appending to existing vector store at {persist_directory}\")\n",
        "\n",
        "    # Create a Chroma vector store instance with the specified directory and embeddings.\n",
        "    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "\n",
        "    # Get the existing collection from the vector store.\n",
        "    collection = db.get()\n",
        "\n",
        "    # Extract source file paths from the collection's metadata.\n",
        "    source_file_paths = [metadata['source'] for metadata in collection['metadatas']]\n",
        "\n",
        "    # Process the documents based on the extracted source file paths.\n",
        "    texts = process_documents(source_file_paths)\n",
        "\n",
        "    # Inform the user about the embeddings creation process.\n",
        "    print(f\"Creating embeddings. May take some minutes...\")\n",
        "\n",
        "       # Check if 'texts' is not empty before adding documents to the vector store\n",
        "    if texts:\n",
        "        # Add the processed documents to the vector store.\n",
        "        db.add_documents(texts)\n",
        "    else:\n",
        "        print(\"No documents to add. Skipping insertion.\")\n",
        "else:\n",
        "    # If the vector store does not exist, create a new one.\n",
        "    print(\"Creating a new vector store\")\n",
        "\n",
        "    # Process documents without specifying ignored files (default behavior).\n",
        "    texts = process_documents()\n",
        "\n",
        "    # Inform the user about the embeddings creation process.\n",
        "    print(f\"Creating embeddings. May take some minutes...\")\n",
        "\n",
        "    # Create a new Chroma vector store with the processed documents and embeddings.\n",
        "    db = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\n",
        "\n",
        "# Persist the vector store.\n",
        "db.persist()\n",
        "\n",
        "# Clear the db variable to free up resources.\n",
        "db = None\n",
        "\n",
        "# Inform the user that the ingestion process is complete.\n",
        "print(f\"Ingestion complete! You can now run privateGPT.py to query your documents\")\n"
      ],
      "metadata": {
        "id": "HI66G_HcxjSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb72d9a-7113-4643-f81f-daed8afd3ca0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to existing vector store at /content/db/\n",
            "Loading documents from ./sor/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading new documents: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No new documents to load\n",
            "Loaded 0 new documents from ./sor/\n",
            "Split into 0 chunks of text (max. 500 tokens each)\n",
            "Creating embeddings. May take some minutes...\n",
            "No documents to add. Skipping insertion.\n",
            "Ingestion complete! You can now run privateGPT.py to query your documents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create settings for Chroma database configuration\n",
        "settings = Settings(\n",
        "    persist_directory=persist_directory,  # Directory for persisting database data\n",
        "    anonymized_telemetry=False  # Disable anonymized telemetry\n",
        ")\n",
        "\n",
        "# Create Hugging Face embeddings model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "# Create a persistent Chroma database client\n",
        "chroma_client = chromadb.PersistentClient(\n",
        "    settings=settings,  # Database settings\n",
        "    path=persist_directory  # Path to the database directory\n",
        ")\n",
        "\n",
        "# Create a Chroma vector store instance\n",
        "db = Chroma(\n",
        "    persist_directory=persist_directory,  # Directory for persisting vector store data\n",
        "    embedding_function=embeddings,  # Embeddings function\n",
        "    client_settings=settings,  # Database settings\n",
        "    client=chroma_client  # Chroma client\n",
        ")\n",
        "\n",
        "# Create a retriever for document retrieval\n",
        "retriever = db.as_retriever(\n",
        "    search_kwargs={\"k\": target_source_chunks}  # Search settings (e.g., number of search results)\n",
        ")\n"
      ],
      "metadata": {
        "id": "pk7vv2QczkIx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store callback handlers (you can add handlers here if needed)\n",
        "callbacks = []\n",
        "\n",
        "# Prepare the Language Model (LLM) based on the specified model_type\n",
        "match model_type:\n",
        "    case \"LLAMA\":\n",
        "        # Create an instance of LlamaCpp\n",
        "        llm = LlamaCpp(\n",
        "            model_path=model_path,  # Path to the LlamaCpp model\n",
        "            max_tokens=model_n_ctx,  # Maximum number of tokens in generated text\n",
        "            n_batch=model_n_batch,  # Batch size for text generation\n",
        "            callbacks=callbacks,    # List of callback handlers\n",
        "            verbose=False           # Set to True for verbose output\n",
        "        )\n",
        "    case \"GPT4All\":\n",
        "        # Create an instance of GPT4All\n",
        "        llm = GPT4All(\n",
        "            model=model_path,       # Path to the GPT4All model\n",
        "            max_tokens=model_n_ctx, # Maximum number of tokens in generated text\n",
        "            backend='gptj',        # Specify the backend (e.g., 'gptj')\n",
        "            n_batch=model_n_batch,  # Batch size for text generation\n",
        "            callbacks=callbacks,    # List of callback handlers\n",
        "            verbose=False           # Set to True for verbose output\n",
        "        )\n",
        "    case _default:\n",
        "        # Raise an exception if the model_type is not supported\n",
        "        raise Exception(f\"Model type {model_type} is not supported. Please choose one of the following: LlamaCpp, GPT4All\")\n"
      ],
      "metadata": {
        "id": "Ews-tZbd0rgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df034fa1-2d6d-4a37-8a06-1f2d11d983bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found model file at  /content/drive/MyDrive/Colab/Models/ggml-gpt4all-j-v1.3-groovy.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 'hide_source' to True or False as needed\n",
        "hide_source = True  # Set to True to hide source documents, False to show them\n",
        "\n",
        "# Set 'mute_stream' to True or False as needed\n",
        "mute_stream = True  # Set to True to mute stream output, False to allow it\n",
        "\n",
        "# Create a RetrievalQA instance for question-answering\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,                       # The language model (LLM) instance\n",
        "    chain_type=\"stuff\",            # Chain type (specific to the application)\n",
        "    retriever=retriever,           # Document retriever instance\n",
        "    return_source_documents=not hide_source  # Whether to return source documents in responses\n",
        ")\n"
      ],
      "metadata": {
        "id": "TOnUUDaFEOmr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Prompt the user to enter a query\n",
        "    query = input(\"\\nEnter a query: \")\n",
        "\n",
        "    # Check if the user wants to exit the loop\n",
        "    if query == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Check if the query is empty and continue to the next iteration if it is\n",
        "    if query.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    # Get the answer from the question-answering system\n",
        "    start = time.time()  # Record the start time for performance measurement\n",
        "    res = qa(query)  # Query the question-answering system using the user's query\n",
        "    answer, docs = res['result'], [] if hide_source else res['source_documents']  # Extract answer and source documents\n",
        "    end = time.time()  # Record the end time for performance measurement\n",
        "\n",
        "    # Print the result\n",
        "    print(\"\\n\\n> Question:\")  # Print the user's query\n",
        "    print(query)\n",
        "    print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")  # Print the answer and query response time\n",
        "    print(answer)\n",
        "\n",
        "    # Print the relevant sources used for the answer, if not hiding sources\n",
        "    if not hide_source:\n",
        "        for document in docs:\n",
        "            print(\"\\n> \" + document.metadata[\"source\"] + \":\")  # Print the source document's metadata\n",
        "            print(document.page_content)  # Print the content of the source document\n"
      ],
      "metadata": {
        "id": "BTee35ITXcRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "e59ce4c5-4bb3-4327-fcb6-0bcb35bf18c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a query: Qu ID tiene el distribuidor Zapata?\n",
            "\n",
            "\n",
            "> Question:\n",
            "Qu ID tiene el distribuidor Zapata?\n",
            "\n",
            "> Answer (took 172.81 s.):\n",
            " The given context does not provide information about the specific ID of the distributor named \"ZapaTa\".\n",
            "\n",
            "Enter a query: Dame los distritos de Ford\n",
            "\n",
            "\n",
            "> Question:\n",
            "Dame los distritos de Ford\n",
            "\n",
            "> Answer (took 170.72 s.):\n",
            " The following are the list of Distrito M's for Ford in Mexico, according to context provided: \n",
            "- M1 (1956) - sedan and wagon models\n",
            "- M2 (1960) - station wagons only\n",
            "- M3 (1963) - sedans and coupes\n",
            "- M4 (1967) - fullsize cars with a V8 engine\n",
            "- M5 (1970) - midsize car, available as a coupe or sedan \n",
            "- M6 (1972) - mid-sized luxury car that was also sold in the United States under the name Lincoln Continental.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c30afa51a4a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Prompt the user to enter a query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter a query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Check if the user wants to exit the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}